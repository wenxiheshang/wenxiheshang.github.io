---
'title': '复习 TensorFlow'
'date': 2017-09-16
---
# 复习 TensorFlow

## 什么是 TensorFlow

TensorFlow 是一款 Google 开源的用于搭建并训练神经网络的框架，底层由 C++ 编写，但提供了完善的 Python API，此外似乎还有 Java 和 Go 的 API。

TF 相当于一门用于科学计算的语言，理论上可以高效运行各种类型的科学计算任务，当然最适合神经网络。

TF 将计算过程抽象为张量流，流动过程由节点控制，包括流动类型和方向。现在以我的理解，除了各种运算类型的节点外，还有一些原地而生的节点。

这是什么意思呢？TF 里的每一个节点都代表着某种运算，但运算在我们通常的认知里，都需要至少两个元素参与，就像加减乘除，矩阵乘法等。但对于 TF 中的节点，运算指代的范围更抽象，这里的运算代表「此处发生了数据的变动」。照这样的理解，TF 中的 「常量节点」、「变量节点」与「占位节点」中的节点也确实是一种运算，这种运算不涉及两个以上的元素，但是节点本身确实「无中生有」地提供了一个数据。**对一个节点而言，并不知道其它节点中具体发生的事情，只是把其它节点流向自己的数据进行处理，仅此而已。**

## TensorFlow 怎么用

上面也提到了，TF 的主要用途就是搭建神经网络模型。

那怎么搭呢？

一个神经网络，分为很多层。每一层都需要设置一些运算图，图由节点流串联而成。可以用「变量节点」标记出需要更新的节点。

每一层搭建是这样的，然后层与层之间再根据某种方法连接起来。

**本质上，神经网络是一个超级巨大的微分方程，而我们只是依据 TF 提供的手段把神经网络表示出来，具体的计算全部交给 TF 就可以。**

## 结语

马上要去实习了，实习期间会经常使用 TF，此外还有 Theano。现在自己对这两个框架都不是特别熟，深入理解更是谈不上。这两天入职前先好好看看，之后实习时，好好干。